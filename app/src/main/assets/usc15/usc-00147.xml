<?xml version="1.0" encoding="UTF-8"?>
<chapter>
<num>CHAPTER 117—</num>
<heading>IDENTIFYING OUTPUTS OF GENERATIVE ADVERSARIAL NETWORKS</heading>
<section>
<num>§ 9201.</num>
<heading> Findings</heading>
<chapeau class="indent0">Congress finds the following:</chapeau>
<paragraph class="indent1">
<num>(1)</num>
<content> Gaps currently exist on the underlying research needed to develop tools that detect videos, audio files, or photos that have manipulated or synthesized content, including those generated by generative adversarial networks. Research on digital forensics is also needed to identify, preserve, recover, and analyze the provenance of digital artifacts.</content>
</paragraph>
<paragraph class="indent1">
<num>(2)</num>
<content> The National Science Foundation’s focus to support research in artificial intelligence through computer and information science and engineering, cognitive science and psychology, economics and game theory, control theory, linguistics, mathematics, and philosophy, is building a better understanding of how new technologies are shaping the society and economy of the United States.</content>
</paragraph>
<paragraph class="indent1">
<num>(3)</num>
<content> The National Science Foundation has identified the “10 Big Ideas for NSF Future Investment” including “Harnessing the Data Revolution” and the “Future of Work at the Human-Technology Frontier”, with artificial intelligence is a critical component.</content>
</paragraph>
<paragraph class="indent1">
<num>(4)</num>
<content> The outputs generated by generative adversarial networks should be included under the umbrella of research described in paragraph (3) given the grave national security and societal impact potential of such networks.</content>
</paragraph>
<paragraph class="indent1">
<num>(5)</num>
<content> Generative adversarial networks are not likely to be utilized as the sole technique of artificial intelligence or machine learning capable of creating credible deepfakes. Other techniques may be developed in the future to produce similar outputs.</content>
</paragraph>
<sourceCredit>(<ref>Pub. L. 116–258, § 2</ref>, <date date="2020-12-23">Dec. 23, 2020</date>, <ref>134 Stat. 1150</ref>.)</sourceCredit>
</section>
<section>
<num>§ 9202.</num>
<heading> NSF support of research on manipulated or synthesized content and information security</heading>
<chapeau class="indent0">The Director of the National Science Foundation, in consultation with other relevant Federal agencies, shall support merit-reviewed and competitively awarded research on manipulated or synthesized content and information authenticity, which may include—</chapeau>
<paragraph class="indent1">
<num>(1)</num>
<content> fundamental research on digital forensic tools or other technologies for verifying the authenticity of information and detection of manipulated or synthesized content, including content generated by generative adversarial networks;</content>
</paragraph>
<paragraph class="indent1">
<num>(2)</num>
<content> fundamental research on technical tools for identifying manipulated or synthesized content, such as watermarking systems for generated media;</content>
</paragraph>
<paragraph class="indent1">
<num>(3)</num>
<content> social and behavioral research related to manipulated or synthesized content, including human engagement with the content;</content>
</paragraph>
<paragraph class="indent1">
<num>(4)</num>
<content> research on public understanding and awareness of manipulated and synthesized content, including research on best practices for educating the public to discern authenticity of digital content; and</content>
</paragraph>
<paragraph class="indent1">
<num>(5)</num>
<content> research awards coordinated with other federal agencies and programs, including the Defense Advanced Research Projects Agency and the Intelligence Advanced Research Projects Agency,<ref class="footnoteRef" idref="fn002649">1</ref> with coordination enabled by the Networking and Information Technology Research and Development Program.</content>
</paragraph>
<sourceCredit>(<ref>Pub. L. 116–258, § 3</ref>, <date date="2020-12-23">Dec. 23, 2020</date>, <ref>134 Stat. 1151</ref>.)</sourceCredit>
</section>
<section>
<num>§ 9203.</num>
<heading> NIST support for research and standards on generative adversarial networks</heading>
<subsection class="indent2 firstIndent-2">
<num class="bold">(a)</num>
<heading class="bold"> In general</heading>
<content>
<p class="indent0">The Director of the National Institute of Standards and Technology shall support research for the development of measurements and standards necessary to accelerate the development of the technological tools to examine the function and outputs of generative adversarial networks or other technologies that synthesize or manipulate content.</p>
</content>
</subsection>
<subsection class="indent2 firstIndent-2">
<num class="bold">(b)</num>
<heading class="bold"> Outreach</heading>
<chapeau class="indent0">The Director of the National Institute of Standards and Technology shall conduct outreach—</chapeau>
<paragraph class="indent1">
<num>(1)</num>
<content> to receive input from private, public, and academic stakeholders on fundamental measurements and standards research necessary to examine the function and outputs of generative adversarial networks; and</content>
</paragraph>
<paragraph class="indent1">
<num>(2)</num>
<content> to consider the feasibility of an ongoing public and private sector engagement to develop voluntary standards for the function and outputs of generative adversarial networks or other technologies that synthesize or manipulate content.</content>
</paragraph>
</subsection>
<sourceCredit>(<ref>Pub. L. 116–258, § 4</ref>, <date date="2020-12-23">Dec. 23, 2020</date>, <ref>134 Stat. 1151</ref>.)</sourceCredit>
</section>
<section>
<num>§ 9204.</num>
<heading> Generative adversarial network defined</heading>
<content>
<p class="indent0">In this chapter, the term “generative adversarial network” means, with respect to artificial intelligence, the machine learning process of attempting to cause a generator artificial neural network (referred to in this section as the “generator” <ref class="footnoteRef" idref="fn002650">1</ref> and a discriminator artificial neural network (referred to in this section as a “discriminator”) to compete against each other to become more accurate in their function and outputs, through which the generator and discriminator create a feedback loop, causing the generator to produce increasingly higher-quality artificial outputs and the discriminator to increasingly improve in detecting such artificial outputs.</p>
</content>
<sourceCredit>(<ref>Pub. L. 116–258, § 6</ref>, <date date="2020-12-23">Dec. 23, 2020</date>, <ref>134 Stat. 1152</ref>.)</sourceCredit>
</section>
</chapter>